{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ece50362-f207-419f-b380-10ddde304126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Enable tqdm for pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c36130e-b7c9-4bd1-b1b1-ae6b715c0e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded: 2230 rows.\n",
      "Columns filtered successfully.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LOAD DATA\n",
    "# =============================================================================\n",
    "\n",
    "# We load the CSV from Step 5 because it has the 'closing_method' column\n",
    "path_to_file = 'output_files/prs_reviews_with_closure.csv'\n",
    "\n",
    "if not os.path.exists(path_to_file):\n",
    "    print(f\"❌ Error: File not found: {path_to_file}\")\n",
    "    print(\"Please ensure you ran Step 5 successfully.\")\n",
    "else:\n",
    "    # Read CSV (Dates are not critical here, but good practice)\n",
    "    reviews = pd.read_csv(path_to_file)\n",
    "    print(f\"✅ Data loaded: {len(reviews)} rows.\")\n",
    "\n",
    "    # Select only necessary columns to save memory\n",
    "    cols_to_keep = [\n",
    "        'id', 'number', 'agent', 'repo_url', 'html_url', \n",
    "        'closing_method', 'reviews_data', 'review_counts_map', \n",
    "        'has_human_closing_user'\n",
    "    ]\n",
    "    # Check if columns exist\n",
    "    if all(col in reviews.columns for col in cols_to_keep):\n",
    "        reduced_reviews = reviews[cols_to_keep].copy()\n",
    "        print(\"Columns filtered successfully.\")\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: Some columns are missing. Available: {reviews.columns.tolist()}\")\n",
    "        reduced_reviews = reviews.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fab0b38-2ab2-445e-aa9e-6e0dce5cbc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PRs found for analysis: 365\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>number</th>\n",
       "      <th>agent</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>closing_method</th>\n",
       "      <th>reviews_data</th>\n",
       "      <th>review_counts_map</th>\n",
       "      <th>has_human_closing_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3164503419</td>\n",
       "      <td>40</td>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>https://api.github.com/repos/amantus-ai/vibetu...</td>\n",
       "      <td>https://github.com/amantus-ai/vibetunnel/pull/40</td>\n",
       "      <td>Closed</td>\n",
       "      <td>[{'user': 'coderabbitai[bot]', 'state': 'COMME...</td>\n",
       "      <td>{'coderabbitai[bot]': 2}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3138264959</td>\n",
       "      <td>1831</td>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>https://api.github.com/repos/evmts/tevm-monorepo</td>\n",
       "      <td>https://github.com/evmts/tevm-monorepo/pull/1831</td>\n",
       "      <td>Closed</td>\n",
       "      <td>[{'user': 'coderabbitai[bot]', 'state': 'COMME...</td>\n",
       "      <td>{'coderabbitai[bot]': 1}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  number        agent  \\\n",
       "1   3164503419      40  Claude_Code   \n",
       "12  3138264959    1831  Claude_Code   \n",
       "\n",
       "                                             repo_url  \\\n",
       "1   https://api.github.com/repos/amantus-ai/vibetu...   \n",
       "12   https://api.github.com/repos/evmts/tevm-monorepo   \n",
       "\n",
       "                                            html_url closing_method  \\\n",
       "1   https://github.com/amantus-ai/vibetunnel/pull/40         Closed   \n",
       "12  https://github.com/evmts/tevm-monorepo/pull/1831         Closed   \n",
       "\n",
       "                                         reviews_data  \\\n",
       "1   [{'user': 'coderabbitai[bot]', 'state': 'COMME...   \n",
       "12  [{'user': 'coderabbitai[bot]', 'state': 'COMME...   \n",
       "\n",
       "           review_counts_map  has_human_closing_user  \n",
       "1   {'coderabbitai[bot]': 2}                    True  \n",
       "12  {'coderabbitai[bot]': 1}                    True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FILTERING\n",
    "# =============================================================================\n",
    "\n",
    "# 1. Filter PRs that have reviews (string length > 2 means it's not \"[]\")\n",
    "prs_with_review = reduced_reviews[reduced_reviews['reviews_data'].str.len() > 2].copy()\n",
    "\n",
    "# 2. Filter PRs that were REJECTED (Closed without merge)\n",
    "rejected_prs = prs_with_review[prs_with_review['closing_method'] == 'Closed'].copy()\n",
    "\n",
    "# 3. Filter PRs closed by a HUMAN\n",
    "rejected_human_closed = rejected_prs[rejected_prs['has_human_closing_user'] == True].copy()\n",
    "\n",
    "# 4. Filter PRs created by AI AGENTS (Target Population)\n",
    "agentic_rejected_human_closed = rejected_human_closed[rejected_human_closed['agent'] != 'Human'].copy()\n",
    "\n",
    "print(f\"Total PRs found for analysis: {len(agentic_rejected_human_closed)}\")\n",
    "agentic_rejected_human_closed.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e5e102-a04a-483e-ace7-17d1e27ef3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create URLs for fetching comments\n",
    "agentic_rejected_human_closed['review_comment_url'] = (\n",
    "    agentic_rejected_human_closed['repo_url'] \n",
    "    + '/pulls/' \n",
    "    + agentic_rejected_human_closed['number'].astype(str) \n",
    "    + '/comments'\n",
    ")\n",
    "\n",
    "agentic_rejected_human_closed['pr_comment_url'] = (\n",
    "    agentic_rejected_human_closed['repo_url'] \n",
    "    + '/issues/' \n",
    "    + agentic_rejected_human_closed['number'].astype(str) \n",
    "    + '/comments'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcee0af-172a-4fcb-b6e7-2becc6d6e5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded. Cutoff date set to: 2025-12-19\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "GITHUB_TOKEN = \"INSERT-TOKEN\"\n",
    "\n",
    "# --- NEW: CUTOFF DATE FOR REPRODUCIBILITY ---\n",
    "# Only data created on or before this date will be included.\n",
    "# Format: YYYY-MM-DD\n",
    "CUTOFF_DATE = \"2025-12-19\" \n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
    "    \"Accept\": \"application/vnd.github.v3+json\"\n",
    "}\n",
    "\n",
    "if GITHUB_TOKEN == \"INSERT-TOKEN\":\n",
    "    print(\"⚠️ WARNING: Token not configured.\")\n",
    "else:\n",
    "    print(f\"Configuration loaded. Cutoff date set to: {CUTOFF_DATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d18507c-78a2-435b-a145-08b10b130108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FETCH FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def fetch_data_robust(url):\n",
    "    if not url or pd.isna(url):\n",
    "        return []\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code == 403 and 'X-RateLimit-Reset' in response.headers:\n",
    "            reset_time = int(response.headers['X-RateLimit-Reset'])\n",
    "            sleep_time = reset_time - time.time() + 10\n",
    "            if sleep_time > 0:\n",
    "                print(f\"\\n⛔ Rate Limit! Sleeping {sleep_time/60:.1f} min...\")\n",
    "                time.sleep(sleep_time)\n",
    "                return fetch_data_robust(url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "def extract_review_comments(url):\n",
    "    data = fetch_data_robust(url)\n",
    "    extracted = []\n",
    "    \n",
    "    for c in data:\n",
    "        created_at = c.get('created_at', '')\n",
    "        if created_at[:10] > CUTOFF_DATE:\n",
    "            continue \n",
    "            \n",
    "        user_data = c.get('user') or {}\n",
    "        extracted.append({\n",
    "            'id': c.get('id'), # <--- ID ÚNICO DO COMENTÁRIO\n",
    "            'user_login': user_data.get('login'),\n",
    "            'user_type': user_data.get('type'),\n",
    "            'body': c.get('body'),\n",
    "            'author_association': c.get('author_association'),\n",
    "            'created_at': created_at,\n",
    "            'url': c.get('html_url')\n",
    "        })\n",
    "    return extracted\n",
    "\n",
    "def extract_issue_comments(url):\n",
    "    data = fetch_data_robust(url)\n",
    "    extracted = []\n",
    "    \n",
    "    for c in data:\n",
    "        created_at = c.get('created_at', '')\n",
    "        if created_at[:10] > CUTOFF_DATE:\n",
    "            continue\n",
    "\n",
    "        user_data = c.get('user') or {}\n",
    "        app_data = c.get('performed_via_github_app')\n",
    "        \n",
    "        extracted.append({\n",
    "            'id': c.get('id'), # <--- ID ÚNICO DO COMENTÁRIO\n",
    "            'user_login': user_data.get('login'),\n",
    "            'user_type': user_data.get('type'),\n",
    "            'body': c.get('body'),\n",
    "            'author_association': c.get('author_association'),\n",
    "            'app_slug': app_data.get('slug') if app_data else None,\n",
    "            'app_name': app_data.get('name') if app_data else None,\n",
    "            'created_at': created_at,\n",
    "            'url': c.get('html_url')\n",
    "        })\n",
    "    return extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78a8546d-d94b-4302-856d-1c86076e68df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Fetching Code Review Comments (<= 2025-12-19)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 365/365 [03:51<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Fetching General Issue Comments (<= 2025-12-19)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 365/365 [03:30<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"1. Fetching Code Review Comments (<= {CUTOFF_DATE})...\")\n",
    "review_comments_list = [\n",
    "    extract_review_comments(url) \n",
    "    for url in tqdm(agentic_rejected_human_closed['review_comment_url'])\n",
    "]\n",
    "agentic_rejected_human_closed['review_comments_data'] = review_comments_list\n",
    "\n",
    "print(f\"\\n2. Fetching General Issue Comments (<= {CUTOFF_DATE})...\")\n",
    "pr_comments_list = [\n",
    "    extract_issue_comments(url) \n",
    "    for url in tqdm(agentic_rejected_human_closed['pr_comment_url'])\n",
    "]\n",
    "agentic_rejected_human_closed['pr_comments_data'] = pr_comments_list\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "503f9bef-8cfc-48a6-95f6-f2430310a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset dataframe for processing\n",
    "comments_dataset = agentic_rejected_human_closed[[\n",
    "    'id', 'number', 'agent', 'html_url',\n",
    "    'reviews_data',         # From Step 4\n",
    "    'review_comments_data', # Fetched just now\n",
    "    'pr_comments_data'      # Fetched just now\n",
    "]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f592dbb2-60d3-4c79-8d96-a0e6f4828aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 139 review verdicts.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def parse_and_filter_reviews(x):\n",
    "    if pd.isna(x) or x == \"\":\n",
    "        return []\n",
    "    try:\n",
    "        raw_list = ast.literal_eval(x)\n",
    "        filtered = []\n",
    "        for r in raw_list:\n",
    "            submitted_at = r.get('submitted_at', '')\n",
    "            if submitted_at and submitted_at[:10] <= CUTOFF_DATE:\n",
    "                filtered.append(r)\n",
    "        return filtered\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "comments_dataset[\"reviews_data_parsed\"] = comments_dataset[\"reviews_data\"].apply(parse_and_filter_reviews)\n",
    "\n",
    "exploded_reviews = (\n",
    "    comments_dataset\n",
    "    .explode(\"reviews_data_parsed\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "reviews_normalized = pd.json_normalize(exploded_reviews[\"reviews_data_parsed\"])\n",
    "\n",
    "final_all_reviews = pd.concat(\n",
    "    [exploded_reviews.drop(columns=[\"reviews_data\", \"reviews_data_parsed\", \"review_comments_data\", \"pr_comments_data\"]), \n",
    "     reviews_normalized], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "if 'body' in final_all_reviews.columns:\n",
    "    final_all_reviews = final_all_reviews[final_all_reviews['body'].notna() & (final_all_reviews['body'] != '')]\n",
    "    final_all_reviews = final_all_reviews[~final_all_reviews['user'].str.contains('bot', case=False, na=False)]\n",
    "\n",
    "print(f\"Extracted {len(final_all_reviews)} review verdicts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8da894b6-24c1-41bf-8150-e6d3480efb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Comments: Removed 0 duplicates.\n",
      "Final Code Review Comments: 590\n"
     ]
    }
   ],
   "source": [
    "exploded_rc = (\n",
    "    comments_dataset[comments_dataset[\"review_comments_data\"].str.len() > 2]\n",
    "    .explode(\"review_comments_data\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "rc_normalized = pd.json_normalize(exploded_rc[\"review_comments_data\"])\n",
    "\n",
    "final_review_comments = pd.concat(\n",
    "    [exploded_rc.drop(columns=[\"reviews_data\", \"review_comments_data\", \"pr_comments_data\"]),\n",
    "     rc_normalized],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "if 'id' in final_review_comments.columns:\n",
    "    before = len(final_review_comments)\n",
    "    final_review_comments = final_review_comments.drop_duplicates(subset=['id'])\n",
    "    print(f\"Code Comments: Removed {before - len(final_review_comments)} duplicates.\")\n",
    "\n",
    "print(f\"Final Code Review Comments: {len(final_review_comments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9a56eb6-9332-4d91-a3a7-9980cbf61338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Comments: Removed 0 duplicates.\n",
      "Final General Comments: 795\n"
     ]
    }
   ],
   "source": [
    "exploded_prc = (\n",
    "    comments_dataset[comments_dataset[\"pr_comments_data\"].str.len() > 2]\n",
    "    .explode(\"pr_comments_data\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "prc_normalized = pd.json_normalize(exploded_prc[\"pr_comments_data\"])\n",
    "\n",
    "final_pr_comments = pd.concat(\n",
    "    [exploded_prc.drop(columns=[\"reviews_data\", \"review_comments_data\", \"pr_comments_data\"]),\n",
    "     prc_normalized],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "cols_drop = ['app_slug', 'app_name']\n",
    "final_pr_comments.drop(columns=[c for c in cols_drop if c in final_pr_comments.columns], inplace=True)\n",
    "\n",
    "if 'id' in final_pr_comments.columns:\n",
    "    before = len(final_pr_comments)\n",
    "    final_pr_comments = final_pr_comments.drop_duplicates(subset=['id'])\n",
    "    print(f\"General Comments: Removed {before - len(final_pr_comments)} duplicates.\")\n",
    "\n",
    "print(f\"Final General Comments: {len(final_pr_comments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c67cd9e9-411f-41a7-9ac9-17df2dccd76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: output_files/comments/comments_extracted_from_review_type.csv\n",
      "✅ Saved: output_files/comments/comments_extracted_from_review_comment.csv\n",
      "✅ Saved: output_files/comments/comments_extracted_from_pr_comment.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SAVE RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "# Ensure directory exists\n",
    "output_dir = 'output_files/comments'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 1. Save Review Verdicts (Approved/Changes Requested)\n",
    "final_all_reviews.to_csv(f'{output_dir}/comments_extracted_from_review_type.csv', index=False)\n",
    "print(f\"✅ Saved: {output_dir}/comments_extracted_from_review_type.csv\")\n",
    "\n",
    "# 2. Save Code Comments (Inline) - Only Humans\n",
    "if 'user_type' in final_review_comments.columns:\n",
    "    human_rc = final_review_comments[final_review_comments['user_type'] == 'User']\n",
    "    human_rc.to_csv(f'{output_dir}/comments_extracted_from_review_comment.csv', index=False)\n",
    "    print(f\"✅ Saved: {output_dir}/comments_extracted_from_review_comment.csv\")\n",
    "\n",
    "# 3. Save General Comments - Only Humans\n",
    "if 'user_type' in final_pr_comments.columns:\n",
    "    human_prc = final_pr_comments[final_pr_comments['user_type'] == 'User']\n",
    "    human_prc.to_csv(f'{output_dir}/comments_extracted_from_pr_comment.csv', index=False)\n",
    "    print(f\"✅ Saved: {output_dir}/comments_extracted_from_pr_comment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2430eb9d-1f32-43c0-be3e-907b2256ef38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
